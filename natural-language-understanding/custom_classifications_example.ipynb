{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will be creating a custom model for Watson Natural Language Understanding (NLU) classifications feature using the Train API.\n",
    "\n",
    "We will go through following functionalities:\n",
    "- [How to create training data file](#Create-Training-Data-File)\n",
    "   - [Create a JSON file from scratch](#Create-training-data-from-scratch)\n",
    "   - [Convert data from NLC to NLU format](#Convert-data-from-NLC-to-NLU-format): This describes how we can convert the data available in [Watson Natural Language Classifier data (csv)](https://cloud.ibm.com/docs/natural-language-classifier?topic=natural-language-classifier-using-your-data) format to Natural Language Understanding data (JSON)\n",
    "   - [Fetch data from NLC](#Fetch-data-from-NLC): This describes how we can get the training data from existing NLC classifier and convert it to NLU data format for classifications.\n",
    "- [How to train a classifications model with NLU train API](#Train-Classifications-model-with-NLU)\n",
    "- [How to get status of the model](#Retrieve-custom-categories-model-by-ID)\n",
    "- [How to use the trained model using NLU Analyze API](#Use-the-trained-model-using-NLU-Analyze-API)\n",
    "\n",
    "To start, we will need an NLU instance and an API key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Add your IBM Cloud service credentials here.\n",
    "- If you use IAM service credentials, leave 'username' set to 'apikey'and set 'password' to the value of your IAM API key.\n",
    "- If you use pre-IAM service credentials, set the values to your 'username' and 'password'.\n",
    "\n",
    "Also set 'url' to the URL for your service instance as provided in your service credentials.\n",
    "See the following instructions for getting your own credentials: https://cloud.ibm.com/docs/watson?topic=watson-iam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'apikey'\n",
    "password = 'YOUR_IAM_APIKEY'\n",
    "url = 'NLU_URI'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Data File\n",
    "\n",
    "Classifications training data requires a list of text documents, each annotated by one or more labels. \n",
    "\n",
    "The training data for classification needs to be in following JSON format:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"text\": \"document 1\",\n",
    "        \"labels\": [\"label1\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"document 2\",\n",
    "        \"labels\": [\"label2\", \"label3\"]\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "\n",
    "## Create training data from scratch\n",
    "\n",
    "Create a training data file and save it in json file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\n",
    "    {\n",
    "        \"text\": \"How hot is it today?\",\n",
    "        \"labels\": [\"temperature\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Is it hot outside?\",\n",
    "        \"labels\": [\"temperature\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Will it be uncomfortably hot?\",\n",
    "        \"labels\": [\"temperature\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Will it be sweltering?\",\n",
    "        \"labels\": [\"temperature\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"How cold is it today?\",\n",
    "        \"labels\": [\"temperature\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Will we get snow?\",\n",
    "        \"labels\": [\"conditions\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Are we expecting sunny conditions?\",\n",
    "        \"labels\": [\"conditions\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Is it overcast?\",\n",
    "        \"labels\": [\"conditions\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Will it be cloudy?\",\n",
    "        \"labels\": [\"conditions\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"How much rain will fall today?\",\n",
    "        \"labels\": [\"conditions\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Save Training data in a file\n",
    "import json\n",
    "\n",
    "training_data_filename = 'training_data.json'\n",
    "\n",
    "with open(training_data_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(training_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data from NLC to NLU format \n",
    "\n",
    "This part of the tutorial provides a way of converting the training data stored **locally** in CSV format (as required by [Watson Natural Language Classifier](https://cloud.ibm.com/docs/natural-language-classifier?topic=natural-language-classifier-using-your-data#training-structure)) to classification training data required by NLU classification training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to training data file used to train Natural Language Classifier\n",
    "nlc_training_data_file_name = 'nlc_training_data.csv'\n",
    "\n",
    "## Imports\n",
    "\n",
    "import csv\n",
    "import json\n",
    "\n",
    "\n",
    "def convert_nlc_to_nlu(filename):\n",
    "    \n",
    "    nlu_data = []\n",
    "\n",
    "    with open(nlc_training_data_file_name, 'r', encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            text = row[0]\n",
    "            labels = row[1:]\n",
    "            # Convert the text and label in NLU training data JSON object\n",
    "            data_dict = {\n",
    "                'text': text,\n",
    "                'labels': labels\n",
    "            }\n",
    "            nlu_data.append(data_dict)\n",
    "\n",
    "    return nlu_data\n",
    "\n",
    "nlu_data = convert_nlc_to_nlu(nlc_training_data_file_name)\n",
    "        \n",
    "# Save Training data in a file\n",
    "training_data_filename = 'training_data.json'\n",
    "\n",
    "with open(training_data_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(nlu_data, f, indent=4)\n",
    "\n",
    "print('Data successfully converted to NLU format and saved locally in ' + training_data_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch data from NLC\n",
    "\n",
    "This part of the tutorial provides a way of extracting the training data from an **already** trained Natural Language Classifier (NLC) and converting it into NLU classifications training data format. For extracting the data from existing NLC classifier, you would need to provide NLC apikey and the classifier URL. Classifier URL can be obtained by making a GET call to NLC as per the API documentation provided [here](https://cloud.ibm.com/apidocs/natural-language-classifier#getclassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add NLC Credentials\n",
    "NLC_USERNAME = \"apikey\"\n",
    "NLC_API_KEY = \"NLC_API_KEY\"\n",
    "\n",
    "# Add the classifier URL returned by NLC. Should contain the instance id and classifier id\n",
    "NLC_CLASSIFIER_URL = \"NLC_URL\"\n",
    "\n",
    "\n",
    "import json\n",
    "import ntpath\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "from contextlib import closing\n",
    "\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "\n",
    "# Provide the filename to save the data downloaded from existing NLC classifier\n",
    "nlc_training_data_file_name = \"nlc_training_data.csv\"\n",
    "\n",
    "# Fetch data from NLC\n",
    "with open(nlc_training_data_file_name, 'w', encoding='utf-8') as out_file:\n",
    "    uri = \"{}/training_data\".format(NLC_CLASSIFIER_URL)\n",
    "    with closing(requests.get(uri, auth=(NLC_USERNAME, NLC_API_KEY), verify=False, stream=True)) as res:\n",
    "        lines = (line.decode('utf-8') for line in res.iter_lines())\n",
    "        csv_writer = csv.writer(out_file)\n",
    "        for row in csv.reader(lines):\n",
    "            csv_writer.writerow(row)\n",
    "\n",
    "\n",
    "# Convert to NLU format    \n",
    "nlu_data = convert_nlc_to_nlu(nlc_training_data_file_name)\n",
    "        \n",
    "# Save Training data in a file\n",
    "training_data_filename = 'training_data.json'\n",
    "\n",
    "with open(training_data_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(nlu_data, f, indent=4)\n",
    "    \n",
    "print('Data successfully converted to NLU format and saved locally in ' + training_data_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifications model with NLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating custom model...\n",
      "Model creation returned:  201\n",
      "\n",
      "Custom model training started...\n",
      "Custom Model ID:  a39b5357-c0f7-4d30-98c7-d4724c73806f\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ntpath\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "\n",
    "######### Create parameters required for making a call to NLU ######### \n",
    "feature_to_train = 'classifications'\n",
    "\n",
    "headers = {}\n",
    "\n",
    "data = {\n",
    "    'name':'Classifications model #1',\n",
    "    'language':'en',\n",
    "    'version':'1.0.1'\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'version': '2021-03-25'\n",
    "}\n",
    "\n",
    "uri = url + '/v1/models/{}'.format(feature_to_train)\n",
    "\n",
    "\n",
    "print('\\nCreating custom model...')\n",
    "\n",
    "training_data_filename = 'training_data.json'\n",
    "\n",
    "######### Make a call to NLU to train the model ######### \n",
    "with open(training_data_filename, 'rb') as f:\n",
    "    response = requests.post(uri,\n",
    "                         params=params,\n",
    "                         data=data,\n",
    "                         headers=headers,\n",
    "                         files={'training_data': (ntpath.basename(training_data_filename), f, 'application/json')},\n",
    "                         auth=(username, password),\n",
    "                         verify=False,\n",
    "                        )\n",
    "\n",
    "######### Parse response from NLU ######### \n",
    "    \n",
    "print('Model creation returned: ', response.status_code)\n",
    "\n",
    "if response.status_code != 201:\n",
    "    print('Failed to create model')\n",
    "    print(response.text)\n",
    "else:\n",
    "    print('\\nCustom model training started...')\n",
    "    response_json = response.json()\n",
    "    model_id = response_json['model_id']\n",
    "    print('Custom Model ID: ', model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve classifications model by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[4mResponse from NLU:\u001b[4m\u001b[0m\n",
      "\n",
      "Status:  200\n",
      "Response body: {\n",
      "    \"created\": \"2021-03-15T07:31:01Z\",\n",
      "    \"description\": null,\n",
      "    \"features\": [\n",
      "        \"classifications\"\n",
      "    ],\n",
      "    \"language\": \"en\",\n",
      "    \"last_deployed\": \"2021-03-15T07:36:59Z\",\n",
      "    \"last_trained\": \"2021-03-15T07:31:01Z\",\n",
      "    \"model_id\": \"a39b5357-c0f7-4d30-98c7-d4724c73806f\",\n",
      "    \"model_version\": \"1.0.1\",\n",
      "    \"name\": \"Classifications model #1\",\n",
      "    \"status\": \"available\",\n",
      "    \"user_metadata\": null,\n",
      "    \"version\": \"1.0.1\",\n",
      "    \"version_description\": null,\n",
      "    \"workspace_id\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "params = {\n",
    "    'version': '2021-02-15'\n",
    "}\n",
    "\n",
    "uri = url + '/v1/models/classifications/' + model_id\n",
    "\n",
    "######### Make a call to NLU ######### \n",
    "\n",
    "response = requests.get(uri, auth=(username, password), params=params, verify=False, headers=headers)\n",
    "\n",
    "######### Parse response from NLU ######### \n",
    "\n",
    "print('\\033[1m'+ '\\033[4m' + 'Response from NLU:' + '\\033[4m' + '\\033[0m')\n",
    "\n",
    "print('\\nStatus: ', response.status_code)\n",
    "\n",
    "response_json = response.json()\n",
    "print(\"Response body:\", json.dumps(response_json, indent=4, sort_keys=True), )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the trained model using NLU Analyze API\n",
    "\n",
    "Once the model is trained, the status from the get request above will turn to `available`. Once the model is `available`, you can make the analyze request using the `model_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully analyzed request. Response from NLU:\n",
      "\n",
      "{\n",
      "    \"classifications\": [\n",
      "        {\n",
      "            \"class_name\": \"temperature\",\n",
      "            \"confidence\": 0.562519\n",
      "        },\n",
      "        {\n",
      "            \"class_name\": \"conditions\",\n",
      "            \"confidence\": 0.433996\n",
      "        }\n",
      "    ],\n",
      "    \"language\": \"en\",\n",
      "    \"usage\": {\n",
      "        \"features\": 0,\n",
      "        \"text_characters\": 36,\n",
      "        \"text_units\": 1\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "######### Create request #########\n",
    "\n",
    "analyze_request_data = {\n",
    "        \"text\":\"What is the expected high for today?\",\n",
    "        \"language\": \"en\",\n",
    "        \"features\": {\n",
    "            \"classifications\": {\n",
    "                \"model\": model_id\n",
    "            }\n",
    "        }\n",
    "}\n",
    "\n",
    "uri = url + '/v1/analyze'\n",
    "\n",
    "params = {\n",
    "    'version': '2021-02-15'\n",
    "}\n",
    "\n",
    "headers = {'Content-Type' : 'application/json'}\n",
    "\n",
    "######### Make a call to NLU #########\n",
    "\n",
    "response = requests.post(uri,\n",
    "                         params=params,\n",
    "                         json=analyze_request_data,\n",
    "                         headers=headers,\n",
    "                         auth=(username, password),\n",
    "                         verify=False,\n",
    "                        )\n",
    "\n",
    "if response.status_code != 200:\n",
    "    print('Failed to make request to model. Reason:')\n",
    "    print(response.text)\n",
    "\n",
    "else:\n",
    "    response_json = response.json()\n",
    "\n",
    "    print(\"Successfully analyzed request. Response from NLU:\\n\")\n",
    "    print(json.dumps(response_json, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
